"""
APScheduler ê¸°ë°˜ ìë™ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬

ë§¤ì¼ íŠ¹ì • ì‹œê°„ì— ìë™ìœ¼ë¡œ Upbit ìº”ë“¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:
  - REDIS_HOST: Redis í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸: localhost)
  - REDIS_PORT: Redis í¬íŠ¸ (ê¸°ë³¸: 6379)
  - SCHEDULER_HOUR: ì‹¤í–‰ ì‹œê°„ ì‹œ (0-23, ê¸°ë³¸: 9, UTC)
  - SCHEDULER_MINUTE: ì‹¤í–‰ ë¶„ (0-59, ê¸°ë³¸: 0)
  - ENABLE_SCHEDULER: ìŠ¤ì¼€ì¤„ëŸ¬ í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸: true)
  - SCHEDULER_SYMBOLS: ìˆ˜ì§‘í•  ì‹¬ë³¼ (ì½¤ë§ˆë¡œ êµ¬ë¶„, ê¸°ë³¸: KRW-BTC,KRW-ETH,KRW-XRP)
  - SCHEDULER_TIMEFRAMES: ìˆ˜ì§‘í•  íƒ€ì„í”„ë ˆì„ (ì½¤ë§ˆë¡œ êµ¬ë¶„, ê¸°ë³¸: 1H,1D)
"""

import logging
import os
from datetime import datetime, timezone
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import redis
from rq import Queue
from backend.app.jobs import fetch_candles_job, batch_fetch_candles_job

logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ê¸°ë³¸ê°’ í¬í•¨)
REDIS_HOST = os.getenv('REDIS_HOST', 'localhost')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))
SCHEDULER_HOUR = int(os.getenv('SCHEDULER_HOUR', 9))  # UTC ê¸°ì¤€
SCHEDULER_MINUTE = int(os.getenv('SCHEDULER_MINUTE', 0))
ENABLE_SCHEDULER = os.getenv('ENABLE_SCHEDULER', 'true').lower() == 'true'

# ê¸°ë³¸ ì‹¬ë³¼ ë° íƒ€ì„í”„ë ˆì„ ì„¤ì •
DEFAULT_SYMBOLS = os.getenv('SCHEDULER_SYMBOLS', 'KRW-BTC,KRW-ETH,KRW-XRP').split(',')
DEFAULT_TIMEFRAMES = os.getenv('SCHEDULER_TIMEFRAMES', '1H,1D').split(',')

# Redis ì—°ê²°
redis_conn = None
scheduler = None
last_run_result = None  # ë§ˆì§€ë§‰ ì‹¤í–‰ ê²°ê³¼
last_run_time = None    # ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê°„
job_history = []        # ì‘ì—… ì‹¤í–‰ ê¸°ë¡ (ìµœê·¼ 10ê°œ)


def init_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”"""
    global scheduler, redis_conn

    if not ENABLE_SCHEDULER:
        logger.warning("âš ï¸  ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤ (ENABLE_SCHEDULER=false)")
        return False

    if scheduler is None:
        scheduler = BackgroundScheduler()

        try:
            redis_conn = redis.Redis(
                host=REDIS_HOST,
                port=REDIS_PORT,
                db=0,
                socket_connect_timeout=5
            )
            redis_conn.ping()
            logger.info(f"âœ… Redis ì—°ê²° ì„±ê³µ ({REDIS_HOST}:{REDIS_PORT})")
        except Exception as e:
            logger.error(f"âŒ Redis ì—°ê²° ì‹¤íŒ¨ ({REDIS_HOST}:{REDIS_PORT}): {e}")
            return False

        return True

    return True


def schedule_daily_collection(
    symbols: list = None,
    timeframes: list = None,
    hour: int = None,
    minute: int = None,
    days: int = 1,
    overwrite: bool = False
):
    """
    ë§¤ì¼ íŠ¹ì • ì‹œê°„ì— ë°ì´í„° ìˆ˜ì§‘ì„ ìŠ¤ì¼€ì¤„

    Args:
        symbols: ìˆ˜ì§‘í•  ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸: DEFAULT_SYMBOLS)
        timeframes: ìˆ˜ì§‘í•  íƒ€ì„í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸: DEFAULT_TIMEFRAMES)
        hour: ì‹¤í–‰ ì‹œê°„ (0-23, UTC ê¸°ì¤€, ê¸°ë³¸: SCHEDULER_HOUR)
        minute: ì‹¤í–‰ ë¶„ (0-59, ê¸°ë³¸: SCHEDULER_MINUTE)
        days: ìˆ˜ì§‘ ê¸°ê°„ (ìµœê·¼ Nì¼)
        overwrite: ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸° ì—¬ë¶€
    """
    global scheduler, redis_conn, last_run_result, last_run_time

    # ê¸°ë³¸ê°’ ì„¤ì •
    if symbols is None:
        symbols = DEFAULT_SYMBOLS
    if timeframes is None:
        timeframes = DEFAULT_TIMEFRAMES
    if hour is None:
        hour = SCHEDULER_HOUR
    if minute is None:
        minute = SCHEDULER_MINUTE

    if not init_scheduler():
        logger.error("ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False

    def job_function():
        """ìŠ¤ì¼€ì¤„ ì‘ì—… í•¨ìˆ˜"""
        global last_run_result, last_run_time, job_history

        run_start = datetime.now(timezone.utc)
        logger.info(f"[ìë™ ìˆ˜ì§‘ ì‹œì‘] {run_start.isoformat()}")
        logger.info(f"  ì‹¬ë³¼: {', '.join(symbols)}")
        logger.info(f"  íƒ€ì„í”„ë ˆì„: {', '.join(timeframes)}")

        q = Queue('data_ingestion', connection=redis_conn)

        try:
            # ë°°ì¹˜ ì‘ì—…ìœ¼ë¡œ ëª¨ë“  ì‹¬ë³¼/íƒ€ì„í”„ë ˆì„ ìˆ˜ì§‘
            job = q.enqueue(
                batch_fetch_candles_job,
                symbols=symbols,
                timeframes=timeframes,
                days=days,
                overwrite=overwrite
            )

            run_end = datetime.now(timezone.utc)
            result = {
                'status': 'queued',
                'job_id': job.id,
                'start_time': run_start.isoformat(),
                'end_time': run_end.isoformat(),
                'symbols': symbols,
                'timeframes': timeframes
            }

            last_run_result = result
            last_run_time = run_start

            # íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 10ê°œë§Œ ìœ ì§€)
            job_history.append(result)
            if len(job_history) > 10:
                job_history.pop(0)

            logger.info(f"âœ… ë°°ì¹˜ ì‘ì—… ì¶”ê°€ë¨ - Job ID: {job.id}")
            return True
        except Exception as e:
            run_end = datetime.now(timezone.utc)
            result = {
                'status': 'failed',
                'error': str(e),
                'start_time': run_start.isoformat(),
                'end_time': run_end.isoformat()
            }

            last_run_result = result
            last_run_time = run_start
            job_history.append(result)
            if len(job_history) > 10:
                job_history.pop(0)

            logger.error(f"âŒ ì‘ì—… ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False

    # ê¸°ì¡´ ì‘ì—… ì œê±° (ì¤‘ë³µ ë°©ì§€)
    if scheduler and scheduler.get_job('daily_data_collection'):
        scheduler.remove_job('daily_data_collection')

    # ë§¤ì¼ ì§€ì • ì‹œê°„ì— ì‹¤í–‰í•˜ë„ë¡ ìŠ¤ì¼€ì¤„
    if scheduler:
        scheduler.add_job(
            job_function,
            CronTrigger(hour=hour, minute=minute),
            id='daily_data_collection',
            name='Daily Data Collection',
            replace_existing=True
        )

        logger.info(f"âœ… ìŠ¤ì¼€ì¤„ ì„¤ì • ì™„ë£Œ")
        logger.info(f"  ì‹¤í–‰ ì‹œê°„: ë§¤ì¼ {hour:02d}:{minute:02d} (UTC)")
        logger.info(f"  ì‹¬ë³¼: {', '.join(symbols)}")
        logger.info(f"  íƒ€ì„í”„ë ˆì„: {', '.join(timeframes)}")

    return True


def start_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
    global scheduler

    if scheduler is None:
        if not init_scheduler():
            logger.error("ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return False

    if not scheduler.running:
        scheduler.start()
        logger.info("ğŸš€ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨")

    return True


def stop_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
    global scheduler

    if scheduler and scheduler.running:
        scheduler.shutdown()
        logger.info("â›” ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ë¨")


def trigger_immediate_batch(
    symbols: list = None,
    timeframes: list = None,
    days: int = 1,
    overwrite: bool = False
):
    """
    ì¦‰ì‹œ ë°°ì¹˜ ì‘ì—… ì‹¤í–‰ (í…ŒìŠ¤íŠ¸/ìš´ì˜ ì ê²€ìš©)

    Args:
        symbols: ìˆ˜ì§‘í•  ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
        timeframes: ìˆ˜ì§‘í•  íƒ€ì„í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸
        days: ìˆ˜ì§‘ ê¸°ê°„
        overwrite: ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸° ì—¬ë¶€

    Returns:
        dict: {'success': bool, 'job_id': str, 'error': str or None}
    """
    global redis_conn, last_run_result, last_run_time, job_history

    if symbols is None:
        symbols = DEFAULT_SYMBOLS
    if timeframes is None:
        timeframes = DEFAULT_TIMEFRAMES

    if redis_conn is None:
        if not init_scheduler():
            return {'success': False, 'error': 'Redis ì—°ê²° ì‹¤íŒ¨'}

    try:
        q = Queue('data_ingestion', connection=redis_conn)

        job = q.enqueue(
            batch_fetch_candles_job,
            symbols=symbols,
            timeframes=timeframes,
            days=days,
            overwrite=overwrite
        )

        run_time = datetime.now(timezone.utc)
        result = {
            'status': 'queued',
            'job_id': job.id,
            'trigger_time': run_time.isoformat(),
            'symbols': symbols,
            'timeframes': timeframes
        }

        last_run_result = result
        last_run_time = run_time
        job_history.append(result)
        if len(job_history) > 10:
            job_history.pop(0)

        logger.info(f"âœ… ì¦‰ì‹œ ë°°ì¹˜ ì‘ì—… ì¶”ê°€ë¨ - Job ID: {job.id}")

        return {
            'success': True,
            'job_id': job.id,
            'error': None
        }
    except Exception as e:
        logger.error(f"âŒ ì¦‰ì‹œ ë°°ì¹˜ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            'success': False,
            'job_id': None,
            'error': str(e)
        }


def get_scheduler_status():
    """
    ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¡°íšŒ (ê°•í™”ëœ ë²„ì „)

    Returns:
        dict: ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ, ë“±ë¡ëœ ì‘ì—…, ìµœê·¼ ì‹¤í–‰ ê²°ê³¼, RQ í ìƒíƒœ
              ENABLE_SCHEDULER=falseì¼ ë•ŒëŠ” ê°„ë‹¨í•œ ìƒíƒœë§Œ ë°˜í™˜
    """
    global scheduler, redis_conn, last_run_result, last_run_time

    # Step 4: ENABLE_SCHEDULER=falseì¼ ë•Œ disabled ìƒíƒœ ë°˜í™˜
    if not ENABLE_SCHEDULER:
        return {
            'enabled': False,
            'running': False,
            'message': 'Scheduler is disabled (ENABLE_SCHEDULER=false)',
            'note': 'Manual triggers are available via POST /api/scheduler/trigger',
            'redis': {
                'host': REDIS_HOST,
                'port': REDIS_PORT,
                'connected': False
            },
            'scheduled_jobs': [],
            'last_run': {
                'time': None,
                'result': None
            },
            'job_history': [],
            'rq_queue': {
                'size': 0,
                'error': None
            },
            'configuration': {
                'hour': SCHEDULER_HOUR,
                'minute': SCHEDULER_MINUTE,
                'symbols': DEFAULT_SYMBOLS,
                'timeframes': DEFAULT_TIMEFRAMES
            }
        }

    status = {
        'enabled': ENABLE_SCHEDULER,
        'running': scheduler.running if scheduler else False,
        'redis': {
            'host': REDIS_HOST,
            'port': REDIS_PORT,
            'connected': False
        },
        'scheduled_jobs': [],
        'last_run': {
            'time': last_run_time.isoformat() if last_run_time else None,
            'result': last_run_result
        },
        'job_history': job_history[-5:],  # ìµœê·¼ 5ê°œë§Œ
        'rq_queue': {
            'size': 0,
            'error': None
        },
        'configuration': {
            'hour': SCHEDULER_HOUR,
            'minute': SCHEDULER_MINUTE,
            'symbols': DEFAULT_SYMBOLS,
            'timeframes': DEFAULT_TIMEFRAMES
        }
    }

    # Redis ì—°ê²° ìƒíƒœ í™•ì¸
    if redis_conn:
        try:
            redis_conn.ping()
            status['redis']['connected'] = True

            # RQ í í¬ê¸° í™•ì¸
            try:
                queue_size = redis_conn.llen('rq:queue:data_ingestion')
                status['rq_queue']['size'] = queue_size
            except Exception as e:
                status['rq_queue']['error'] = str(e)
        except Exception as e:
            status['redis']['connected'] = False
            status['redis']['error'] = str(e)

    # ìŠ¤ì¼€ì¤„ëœ ì‘ì—… ëª©ë¡
    if scheduler:
        for job in scheduler.get_jobs():
            status['scheduled_jobs'].append({
                'id': job.id,
                'name': job.name,
                'trigger': str(job.trigger),
                'next_run': job.next_run_time.isoformat() if job.next_run_time else None
            })

    return status
