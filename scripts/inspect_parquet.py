#!/usr/bin/env python3
"""
Parquet íŒŒì¼ ê²€ì¦ ë° í†µê³„ ì¶œë ¥ ìŠ¤í¬ë¦½íŠ¸

Parquet íŒŒì¼ì˜ ë‚´ìš©ì„ ê²€ì¦í•˜ê³  ì£¼ìš” í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
pandas/pyarrowê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ê¸°ë³¸ ì •ë³´ë¥¼ ì¶œë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆ:
  python scripts/inspect_parquet.py --path data/KRW-BTC/1H/2025.parquet
  python scripts/inspect_parquet.py --path data/KRW-BTC/1H/2025.parquet --verbose
"""

import sys
import argparse
from pathlib import Path
from typing import Optional, Dict, Any
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s: %(message)s'
)
logger = logging.getLogger(__name__)


def inspect_parquet_pandas(file_path: Path) -> Dict[str, Any]:
    """
    pandas/pyarrowë¥¼ ì´ìš©í•œ ìƒì„¸ ê²€ì¦
    """
    try:
        import pandas as pd
        import pyarrow.parquet as pq

        # Parquet ë©”íƒ€ë°ì´í„° ì½ê¸°
        parquet_file = pq.ParquetFile(file_path)
        table = parquet_file.read()
        df = table.to_pandas()

        stats = {
            'file_size': file_path.stat().st_size,
            'rows': len(df),
            'columns': list(df.columns),
            'dtypes': df.dtypes.to_dict(),
            'timestamp_min': str(df['timestamp'].min()) if 'timestamp' in df else 'N/A',
            'timestamp_max': str(df['timestamp'].max()) if 'timestamp' in df else 'N/A',
            'numeric_columns': {}
        }

        # ìˆ«ìí˜• ì»¬ëŸ¼ í†µê³„
        numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
        for col in numeric_cols:
            stats['numeric_columns'][col] = {
                'min': float(df[col].min()),
                'max': float(df[col].max()),
                'mean': float(df[col].mean()),
                'std': float(df[col].std()),
            }

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        stats['memory_usage'] = df.memory_usage(deep=True).sum()

        # ê²°ì¸¡ì¹˜ ì²´í¬
        stats['null_counts'] = df.isnull().sum().to_dict()

        return stats

    except ImportError as e:
        logger.warning(f"pandas/pyarrow ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”: {e}")
        return inspect_parquet_basic(file_path)
    except Exception as e:
        logger.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return {}


def inspect_parquet_basic(file_path: Path) -> Dict[str, Any]:
    """
    ê¸°ë³¸ ì •ë³´ë§Œ ì¶œë ¥ (pandas ì—†ì„ ê²½ìš°)
    """
    try:
        import pyarrow.parquet as pq

        parquet_file = pq.ParquetFile(file_path)
        metadata = parquet_file.metadata
        schema = parquet_file.schema_arrow

        stats = {
            'file_size': file_path.stat().st_size,
            'rows': metadata.num_rows,
            'columns': schema.names,
            'note': 'pandas ë¯¸ì„¤ì¹˜ ìƒíƒœ - ê¸°ë³¸ ì •ë³´ë§Œ ì œê³µ',
        }

        return stats

    except Exception as e:
        logger.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {}


def print_stats(stats: Dict[str, Any], verbose: bool = False) -> None:
    """
    í†µê³„ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
    """
    if not stats:
        logger.warning("í†µê³„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return

    print("\n" + "=" * 70)
    print("ğŸ“Š Parquet íŒŒì¼ ê²€ì¦ ê²°ê³¼")
    print("=" * 70)

    # ê¸°ë³¸ ì •ë³´
    print(f"\nğŸ“ ê¸°ë³¸ ì •ë³´:")
    print(f"  íŒŒì¼ í¬ê¸°: {stats.get('file_size', 'N/A'):,} bytes "
          f"({stats.get('file_size', 0) / 1024 / 1024:.2f} MB)")
    print(f"  í–‰(Row) ìˆ˜: {stats.get('rows', 'N/A'):,}")
    print(f"  ì»¬ëŸ¼(Column): {', '.join(stats.get('columns', []))}")

    # íƒ€ì„ìŠ¤íƒ¬í”„ ë²”ìœ„
    if 'timestamp_min' in stats:
        print(f"\nâ° ì‹œê°„ ë²”ìœ„:")
        print(f"  ìµœì†Œ: {stats['timestamp_min']}")
        print(f"  ìµœëŒ€: {stats['timestamp_max']}")

    # ìˆ«ìí˜• ì»¬ëŸ¼ í†µê³„
    if 'numeric_columns' in stats and stats['numeric_columns']:
        print(f"\nğŸ“ˆ ìˆ«ìí˜• ì»¬ëŸ¼ í†µê³„:")
        for col, col_stats in stats['numeric_columns'].items():
            print(f"\n  {col}:")
            print(f"    ìµœì†Œê°’: {col_stats['min']:,.2f}")
            print(f"    ìµœëŒ€ê°’: {col_stats['max']:,.2f}")
            print(f"    í‰ê· : {col_stats['mean']:,.2f}")
            print(f"    í‘œì¤€í¸ì°¨: {col_stats['std']:,.2f}")

    # ê²°ì¸¡ì¹˜ ì •ë³´
    if 'null_counts' in stats:
        null_cols = {k: v for k, v in stats['null_counts'].items() if v > 0}
        if null_cols:
            print(f"\nâš ï¸  ê²°ì¸¡ì¹˜ ê°ì§€:")
            for col, count in null_cols.items():
                print(f"    {col}: {count}ê°œ")
        else:
            print(f"\nâœ… ê²°ì¸¡ì¹˜ ì—†ìŒ")

    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    if 'memory_usage' in stats:
        mem_mb = stats['memory_usage'] / 1024 / 1024
        print(f"\nğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_mb:.2f} MB")

    # ë°ì´í„° íƒ€ì…
    if verbose and 'dtypes' in stats:
        print(f"\nğŸ“‹ ë°ì´í„° íƒ€ì…:")
        for col, dtype in stats['dtypes'].items():
            print(f"    {col}: {dtype}")

    # ë©”ëª¨ ì‚¬í•­
    if 'note' in stats:
        print(f"\nğŸ“ ë©”ëª¨: {stats['note']}")

    print("\n" + "=" * 70 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description='Parquet íŒŒì¼ ê²€ì¦ ë° í†µê³„ ì¶œë ¥ ë„êµ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )

    parser.add_argument('--path', required=True, help='ê²€ì¦í•  Parquet íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--verbose', '-v', action='store_true', help='ìƒì„¸ ì •ë³´ ì¶œë ¥')

    args = parser.parse_args()

    # íŒŒì¼ ê²½ë¡œ ê²€ì¦
    file_path = Path(args.path)
    if not file_path.exists():
        logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
        sys.exit(1)

    if not file_path.suffix.lower() == '.parquet':
        logger.warning(f"íŒŒì¼ í™•ì¥ìê°€ .parquetì´ ì•„ë‹™ë‹ˆë‹¤: {file_path.suffix}")

    # ê²€ì¦ ìˆ˜í–‰
    logger.info(f"íŒŒì¼ ë¶„ì„ ì¤‘: {file_path}")
    stats = inspect_parquet_pandas(file_path)

    # ê²°ê³¼ ì¶œë ¥
    print_stats(stats, verbose=args.verbose)

    # ì„±ê³µ ë°˜í™˜
    if stats:
        sys.exit(0)
    else:
        sys.exit(1)


if __name__ == '__main__':
    main()
