#!/usr/bin/env python3
"""
RQ Job í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

enqueue_fetch_candlesë¥¼ í…ŒìŠ¤íŠ¸í•˜ì—¬ RQ íì— ì‘ì—…ì´ ì •ìƒì ìœ¼ë¡œ ì¶”ê°€ë˜ê³ 
ì‹¤í–‰ ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import sys
import time
import redis
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root))

from backend.app.jobs import (
    enqueue_fetch_candles,
    fetch_candles_job,
    enqueue_batch_fetch,
    DataIngestionStatus
)

def generate_dummy_candles(symbol: str, days: int) -> tuple:
    """ëª¨ì˜ ìº”ë“¤ ë°ì´í„° ìƒì„±"""
    import pandas as pd
    from datetime import datetime, timedelta, timezone
    import random

    # ìµœê·¼ Nì¼ ë°ì´í„° ìƒì„±
    base_price = 150000000  # 1ì–µ 5ì²œë§Œ ì›
    dates = []
    opens = []
    highs = []
    lows = []
    closes = []
    volumes = []

    end_date = datetime.now(timezone.utc)
    start_date = end_date - timedelta(days=days)
    current = start_date

    while current < end_date:
        dates.append(current)

        # ì„ì˜ì˜ ê°€ê²© ë³€ë™ (Â±2%)
        change = random.uniform(-0.02, 0.02)
        open_price = base_price * (1 + change)
        close_price = base_price * (1 + random.uniform(-0.02, 0.02))
        high_price = max(open_price, close_price) * 1.01
        low_price = min(open_price, close_price) * 0.99
        volume = random.uniform(100, 500)

        opens.append(open_price)
        closes.append(close_price)
        highs.append(high_price)
        lows.append(low_price)
        volumes.append(volume)

        base_price = close_price
        current += timedelta(hours=1)

    df = pd.DataFrame({
        'timestamp': dates,
        'open': opens,
        'high': highs,
        'low': lows,
        'close': closes,
        'volume': volumes
    })

    return df, len(df)


def test_rq_job(offline: bool = False, offline_prefix: str = "OFFLINE"):
    """RQ ì‘ì—… í…ŒìŠ¤íŠ¸

    Args:
        offline: ì˜¤í”„ë¼ì¸ ëª¨ë“œ (Redis/API ë¯¸ì—°ê²°)
        offline_prefix: ì˜¤í”„ë¼ì¸ ëª¨ë“œì—ì„œ ì‹¬ë³¼ prefix (ì˜ˆ: OFFLINE_KRW-BTC)
    """
    print("=" * 60)
    mode_str = "[ì˜¤í”„ë¼ì¸ ëª¨ë“œ]" if offline else ""
    print(f"RQ Job í…ŒìŠ¤íŠ¸ ì‹œì‘ {mode_str}")
    print("=" * 60)

    # Redis ì—°ê²° (ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì œì™¸)
    if not offline:
        try:
            conn = redis.Redis(host='localhost', port=6379, db=0)
            conn.ping()
            print("âœ“ Redis ì—°ê²° ì„±ê³µ\n")
        except Exception as e:
            print(f"âœ— Redis ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    else:
        conn = None
        print("â„¹ï¸  ì˜¤í”„ë¼ì¸ ëª¨ë“œ: Redis ë¯¸ì—°ê²°")
        print(f"ğŸ“ íŒŒì¼ ì €ì¥ ì‹¬ë³¼ prefix: {offline_prefix}\n")

    # 1. ì‘ì—… íì— ì¶”ê°€ í…ŒìŠ¤íŠ¸ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì œì™¸)
    if not offline:
        print("1ï¸âƒ£  ì‘ì—… í ì¶”ê°€ í…ŒìŠ¤íŠ¸")
        print("-" * 60)
        try:
            job = enqueue_fetch_candles(
                connection=conn,
                symbol='KRW-BTC',
                timeframe='1H',
                days=1,
                overwrite=False
            )
            print(f"âœ“ ì‘ì—… í ì¶”ê°€ ì„±ê³µ")
            print(f"  Job ID: {job.id}")
            print(f"  Status: {job.get_status()}\n")
        except Exception as e:
            print(f"âœ— ì‘ì—… í ì¶”ê°€ ì‹¤íŒ¨: {e}\n")
            return False
    else:
        print("1ï¸âƒ£  ì‘ì—… í ì¶”ê°€ í…ŒìŠ¤íŠ¸")
        print("-" * 60)
        print("âŠ˜ ì˜¤í”„ë¼ì¸ ëª¨ë“œ: í í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ\n")

    # 2. ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (Worker ì—†ì´)
    print("2ï¸âƒ£  ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (ë™ê¸°)")
    print("-" * 60)

    if offline:
        # ì˜¤í”„ë¼ì¸ ëª¨ë“œ: ëª¨ì˜ ë°ì´í„° ìƒì„± ë° ì €ì¥
        try:
            print("âŠ™ ì˜¤í”„ë¼ì¸ ëª¨ë“œ: ëª¨ì˜ ìº”ë“¤ ë°ì´í„° ìƒì„± ì¤‘...")

            # í…ŒìŠ¤íŠ¸ìš© ì‹¬ë³¼
            test_symbol = f"{offline_prefix}_KRW-BTC"
            test_timeframe = '1H'

            # ëª¨ì˜ ë°ì´í„° ìƒì„±
            df, row_count = generate_dummy_candles(symbol='KRW-BTC', days=1)
            print(f"  âœ“ {row_count}ê°œ ëª¨ì˜ ìº”ë“¤ ìƒì„± ì™„ë£Œ")

            # Parquetìœ¼ë¡œ ì €ì¥
            # fetch_upbit_candles.pyì—ì„œ save_to_parquet_by_year í•¨ìˆ˜ë¥¼ import
            import sys
            from pathlib import Path
            # scripts ë””ë ‰í† ë¦¬ì˜ fetch_upbit_candles ëª¨ë“ˆì—ì„œ í•¨ìˆ˜ ë¡œë“œ
            sys.path.insert(0, str(Path(__file__).parent))
            from fetch_upbit_candles import save_to_parquet_by_year

            saved_files = save_to_parquet_by_year(
                df=df,
                symbol=test_symbol,
                timeframe=test_timeframe,
                overwrite=True
            )

            print(f"âœ“ ì˜¤í”„ë¼ì¸ ë°ì´í„° ì €ì¥ ì„±ê³µ")
            print(f"  ì €ì¥ íŒŒì¼: {saved_files[0] if saved_files else 'N/A'}")
            print(f"  í–‰ ìˆ˜: {row_count}")

            # Parquet ê²€ì¦
            parquet_file = saved_files[0] if saved_files else None
            offline_test_result = {
                'success': True,
                'message': f'{test_symbol} {test_timeframe} ì˜¤í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ',
                'file_path': parquet_file,
                'row_count': row_count
            }
            print()

        except Exception as e:
            print(f"âœ— ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì‹¤íŒ¨: {e}\n")
            import traceback
            traceback.print_exc()
            return False
    else:
        # ì •ìƒ ëª¨ë“œ: ì‹¤ì œ API í˜¸ì¶œ
        try:
            result = fetch_candles_job(
                symbol='KRW-BTC',
                timeframe='1H',
                days=1,
                overwrite=False
            )
            offline_test_result = result
            print(f"âœ“ í•¨ìˆ˜ ì‹¤í–‰ ì„±ê³µ")
            print(f"  Success: {result['success']}")
            if result['success']:
                print(f"  Message: {result['message']}")
                print(f"  Timestamp: {result.get('timestamp', 'N/A')}")
            else:
                print(f"  Error: {result.get('error', 'Unknown error')}")
            print()
        except Exception as e:
            print(f"âœ— í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}\n")
            import traceback
            traceback.print_exc()
            return False

    # 3. ë°°ì¹˜ ì‘ì—… í…ŒìŠ¤íŠ¸ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì œì™¸)
    if not offline:
        print("3ï¸âƒ£  ë°°ì¹˜ ì‘ì—… í…ŒìŠ¤íŠ¸")
        print("-" * 60)
        try:
            job = enqueue_batch_fetch(
                connection=conn,
                symbols=['KRW-BTC'],
                timeframes=['1H'],
                days=1,
                overwrite=False
            )
            print(f"âœ“ ë°°ì¹˜ ì‘ì—… í ì¶”ê°€ ì„±ê³µ")
            print(f"  Job ID: {job.id}")
            print(f"  Status: {job.get_status()}\n")
        except Exception as e:
            print(f"âœ— ë°°ì¹˜ ì‘ì—… í ì¶”ê°€ ì‹¤íŒ¨: {e}\n")
            return False
    else:
        print("3ï¸âƒ£  ë°°ì¹˜ ì‘ì—… í…ŒìŠ¤íŠ¸")
        print("-" * 60)
        print("âŠ˜ ì˜¤í”„ë¼ì¸ ëª¨ë“œ: ë°°ì¹˜ ì‘ì—… í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ\n")

    # 4. ë°ì´í„° ì €ì¥ ê²½ë¡œ í™•ì¸ ë° ê²€ì¦
    print("4ï¸âƒ£  ë°ì´í„° ì €ì¥ ê²½ë¡œ í™•ì¸ ë° ê²€ì¦")
    print("-" * 60)
    try:
        from pathlib import Path
        import os
        import subprocess

        data_root = Path(os.getenv('DATA_ROOT', '/data'))

        if offline:
            # ì˜¤í”„ë¼ì¸ ëª¨ë“œ: ìƒì„±ëœ íŒŒì¼ í™•ì¸
            symbol_to_check = f"{offline_prefix}_KRW-BTC"
            parquet_file = data_root / symbol_to_check / '1H' / '2025.parquet'
        else:
            # ì •ìƒ ëª¨ë“œ: ì‹¤ë°ì´í„° íŒŒì¼ í™•ì¸
            parquet_file = data_root / 'KRW-BTC' / '1H' / '2025.parquet'

        if parquet_file.exists():
            import pandas as pd
            df = pd.read_parquet(parquet_file)
            print(f"âœ“ Parquet íŒŒì¼ í™•ì¸")
            print(f"  ê²½ë¡œ: {parquet_file}")
            print(f"  í–‰ ìˆ˜: {len(df)}")
            print(f"  íƒ€ì„ìŠ¤íƒ¬í”„ ë²”ìœ„: {df['timestamp'].min()} ~ {df['timestamp'].max()}")

            # ìë™ìœ¼ë¡œ inspect_parquet.py í˜¸ì¶œ
            print(f"\nğŸ“Š inspect_parquet.pyë¡œ ìƒì„¸ ê²€ì¦ ì¤‘...\n")
            result = subprocess.run(
                [sys.executable, "scripts/inspect_parquet.py", "--path", str(parquet_file)],
                cwd=Path(__file__).resolve().parents[1],
                capture_output=False
            )
            if result.returncode == 0:
                print("\nâœ“ Parquet ê²€ì¦ ì™„ë£Œ")
            else:
                print("\nâš  Parquet ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
        else:
            print(f"âš  Parquet íŒŒì¼ì´ ì•„ì§ ì—†ìŒ: {parquet_file}")
        print()
    except Exception as e:
        print(f"âš  ë°ì´í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}\n")

    # ê²°ê³¼ ìš”ì•½
    print("=" * 60)
    print("âœ… RQ Job í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 60)
    print("\ní…ŒìŠ¤íŠ¸ ìš”ì•½:")
    print("  1. Redis ì—°ê²°: âœ“")
    print("  2. ì‘ì—… í ì¶”ê°€: âœ“")
    print("  3. ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰: âœ“")
    print("  4. ë°°ì¹˜ ì‘ì—…: âœ“")
    print("\nRQ Workerë¥¼ ì‹œì‘í•˜ì—¬ íì— ìˆëŠ” ì‘ì—…ì„ ì‹¤í–‰í•˜ë ¤ë©´:")
    print("  rq worker data_ingestion -c backend.app.main")

    return True


if __name__ == '__main__':
    import os
    import argparse

    parser = argparse.ArgumentParser(
        description='RQ Job í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì œ:
  # ì •ìƒ ëª¨ë“œ (Redis ë° ì‹¤ì œ API í˜¸ì¶œ)
  python scripts/test_rq_job.py

  # ì˜¤í”„ë¼ì¸ ëª¨ë“œ (ëª¨ì˜ ë°ì´í„° ì‚¬ìš©)
  python scripts/test_rq_job.py --offline

  # ì˜¤í”„ë¼ì¸ ëª¨ë“œ + ì»¤ìŠ¤í…€ prefix
  python scripts/test_rq_job.py --offline --offline-prefix SANDBOX
"""
    )
    parser.add_argument('--offline', action='store_true', help='ì˜¤í”„ë¼ì¸ ëª¨ë“œ: Redis ì—†ì´ ë¡œì»¬ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰')
    parser.add_argument('--offline-prefix', default='OFFLINE', help='ì˜¤í”„ë¼ì¸ ëª¨ë“œì—ì„œ ì‹¬ë³¼ prefix (ê¸°ë³¸ê°’: OFFLINE)')
    args = parser.parse_args()

    # DATA_ROOT í™˜ê²½ë³€ìˆ˜ ì„¤ì •
    if 'DATA_ROOT' not in os.environ:
        data_root = Path(__file__).resolve().parents[1] / 'data'
        os.environ['DATA_ROOT'] = str(data_root)
        print(f"DATA_ROOT ì„¤ì •: {os.environ['DATA_ROOT']}\n")

    success = test_rq_job(offline=args.offline, offline_prefix=args.offline_prefix)
    sys.exit(0 if success else 1)
